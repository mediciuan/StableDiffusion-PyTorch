%%capture
%cd ..
# 셀 1: 패키지 설치 및 임포트
!pip install torch torchvision pillow --quiet
!git clone https://github.com/madebyollin/taesd --quiet
import sys
sys.path.append("taesd")
from taesd.model import TAESD

# 셀 2: 모델 초기화
import torch
dev = torch.device("cuda" if torch.cuda.is_available() else "cpu")
taesd = TAESD().to(dev)

# 셀 3: 이미지 로드 및 함수 정의
from PIL import Image
import torchvision.transforms.functional as TF

test_image = Image.open("uan.jpg").convert("RGB")
test_image = TF.center_crop(TF.resize(test_image, 128), 128)

def summarize_tensor(x):
    return f"{str(tuple(x.shape)).ljust(24)} (min {x.min().item():+.4f} / mean {x.mean().item():+.4f} / max {x.max().item():+.4f})"

def latent_to_visualization(latent):
    latent = TAESD.scale_latents(latent)
    return torch.cat([latent[:3], latent[3:].expand(3, *latent.shape[-2:])], -2)

def demo_taesd_on_image(taesd, image, dev):
    image_raw = TF.to_tensor(image).unsqueeze(0).to(dev)
    with torch.no_grad():
        image_enc = taesd.encoder(image_raw)
        image_dec = taesd.decoder(image_enc).clamp(0, 1)
    print("input image", summarize_tensor(image_raw[0]))
    display(TF.to_pil_image(image_raw[0]))
    print("latents", summarize_tensor(image_enc[0]))
    display(TF.to_pil_image(latent_to_visualization(image_enc[0])))
    print("decoded image", summarize_tensor(image_dec[0]))
    display(TF.to_pil_image(image_dec[0]))

# 셀 4: 실행
demo_taesd_on_image(taesd, test_image, dev)

from PIL import Image
from IPython.display import display

def resize_and_center_crop(image, size):
    # 이미지를 정사각형으로 리사이즈 (비율 유지 X)
    image = image.resize((size, size))
    return image

img_path = "C:/Users/unish/tuning/images/uan.jpg"

try:
    test_image = Image.open(img_path).convert("RGB")
    test_image = resize_and_center_crop(test_image, 128)
    display(test_image)
except Exception as e:
    print(f"Error loading or displaying image: {e}")


def summarize_tensor(x):
    return f"\033[34m{str(tuple(x.shape)).ljust(24)}\033[0m (\033[31mmin {x.min().item():+.4f}\033[0m / \033[32mmean {x.mean().item():+.4f}\033[0m / \033[33mmax {x.max().item():+.4f}\033[0m)"

def latent_to_visualization(latent):
    latent = TAESD.scale_latents(latent)
    return torch.cat([latent[:3], latent[3:].expand(3, *latent.shape[-2:])], -2)

def demo_taesd_on_image(taesd, image, dev):
    image_raw = TF.to_tensor(image).unsqueeze(0).to(dev)
    image_enc = taesd.encoder(image_raw)
    image_dec = taesd.decoder(image_enc).clamp(0, 1)
    
    print("input image", summarize_tensor(image_raw[0]))
    display(TF.to_pil_image(image_raw[0]))

    print("latents", summarize_tensor(image_enc[0]))
    print("(these latents are the same size / scale as SD UNet-generated latents - no extra scale_factor is needed)")
    display(TF.to_pil_image(latent_to_visualization(image_enc[0])))
    
    print("decoded image", summarize_tensor(image_dec[0]))
    display(TF.to_pil_image(image_dec[0]))

demo_taesd_on_image(taesd, test_image, dev)
# 1. 패키지 설치 및 초기화
!pip install torch torchvision pillow --quiet
!git clone https://github.com/madebyollin/taesd

# 2. 라이브러리 임포트
import torch
import torchvision.transforms.functional as TF
from PIL import Image
import sys
sys.path.append("taesd")
from taesd.model import TAESD

# 3. 디바이스 설정
dev = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Device: {dev}")

# 4. TAESD 모델 생성
taesd = TAESD(device=dev)

# 5. 테스트 이미지 로드 (128x128 필수)
test_image = Image.open("uan.jpg").convert("RGB")
test_image = TF.center_crop(TF.resize(test_image, 128), 128)

# 6. 분석 함수 실행
def demo_taesd_on_image(taesd, image, dev):
# ... (이전에 제공한 demo_taesd_on_image 함수 코드 그대로 사용)

demo_taesd_on_image(taesd, test_image, dev)  # 정상 실행













